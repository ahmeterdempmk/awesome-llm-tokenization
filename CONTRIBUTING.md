# Contributing to Awesome LLM Tokenization

First off, thanks for taking the time to contribute! ðŸŽ‰

This project is a curated list of resources related to Large Language Model tokenization. We welcome contributions that add valuable papers, tools, videos, or benchmarks.

## How to Contribute

1.  **Check for Duplicates**: Search the `README.md` to ensure your resource isn't already listed.
2.  **Fork the Repo**: Click the "Fork" button in the top right corner.
3.  **Create a Branch**: `git checkout -b add-my-resource`
4.  **Add Your Resource**: Follow the format guidelines below.
5.  **Commit**: `git commit -m "Add [Resource Name]"`
6.  **Push**: `git push origin add-my-resource`
7.  **Open a Pull Request**: Go to the original repository and click "New Pull Request".

## Content Guidelines

### Relevance
*   The resource must be directly related to **tokenization**.
*   General LLM papers (unless they have a significant section on tokenization) may be rejected.
*   Commercial tools are allowed if they offer a unique value or a free tier/open-source component.

### Formatting
Please follow the existing structure of the list.

**For Papers:**
Please include the Title, Venue (if applicable), Year, and links (arXiv/PDF + GitHub code if available).

Format:
`| **Title** | Venue | Year | [![arXiv](https://img.shields.io/badge/arXiv-ID-b31b1b.svg)](LINK) |`

**For Tools/Libraries:**
Please include the name, a short description, and the link.

Format:
`| **Name** | Description | [![GitHub](https://img.shields.io/badge/GitHub-Code-black)](LINK) |`

## Sorting
*   **Papers**: Generally sorted by **Year (descending)** or by relevance within a category.
*   **Tools**: Sorted by popularity or alphabetical order.

## Questions?
Feel free to open an issue if you have questions about where a resource fits!
